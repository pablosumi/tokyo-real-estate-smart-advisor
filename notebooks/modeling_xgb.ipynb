{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59b959dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6013b532",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. load the stateless preprocessed Data\n",
    "df = pd.read_parquet('../data/tokyo-preprocessed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d00f4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Setup Features (X) and Target (y)\n",
    "# We train on LogTradePrice to handle the skew, but we evaluate on Real Yen.\n",
    "# XGBoost cannot directly handle datetime data\n",
    "target_col = 'LogTradePriceYen'\n",
    "drop_cols = ['TradePriceYen', 'LogTradePriceYen', 'TransactionQuarterEndDate']\n",
    "\n",
    "# Ensure strict time sorting for Time Series Split\n",
    "df = df.sort_values(['TransactionYear', 'TransactionQuarter']).reset_index(drop=True)\n",
    "\n",
    "X = df.drop(columns=drop_cols)\n",
    "y = df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d05b2537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Identify Categorical Columns for Target Encoding\n",
    "# These are the ones that need the \"Stateful\" handling\n",
    "cat_cols = [\n",
    "    'Municipality', \n",
    "    'DistrictName', \n",
    "    'Use', \n",
    "    'Structure', \n",
    "    'LandShape',\n",
    "    'Renovation',\n",
    "    'Purpose',\n",
    "    'Type',\n",
    "    'Region',\n",
    "    'CityPlanning',\n",
    "    'Classification',\n",
    "    'RoadDirection',\n",
    "    'Remarks'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "132e050c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training with 32 features...\n",
      "Fold 1: Train End Year: 2013 | MAE: ¥9,995,546\n",
      "Fold 2: Train End Year: 2016 | MAE: ¥9,974,599\n",
      "Fold 3: Train End Year: 2020 | MAE: ¥9,439,635\n",
      "Fold 4: Train End Year: 2022 | MAE: ¥9,797,243\n",
      "Fold 5: Train End Year: 2023 | MAE: ¥12,598,202\n",
      "\n",
      "Average MAE across folds: ¥10,361,045\n"
     ]
    }
   ],
   "source": [
    "# 4. Initialize Time Series Split\n",
    "# five Splits means we train on the past -> predict the immediate future\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "results = []\n",
    "fold = 0\n",
    "\n",
    "print(f\"Starting Training with {X.shape[1]} features...\")\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    fold += 1\n",
    "    \n",
    "    # --- A. The Split ---\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # --- B. Stateful Transformation (Target Encoding) ---\n",
    "    # CRITICAL: We fit ONLY on X_train. \n",
    "    # The encoder learns \"Minato-ku is expensive\" from the Training data only.\n",
    "    encoder = ce.TargetEncoder(cols=cat_cols, smoothing=10)\n",
    "    \n",
    "    X_train_encoded = encoder.fit_transform(X_train, y_train)\n",
    "    X_test_encoded = encoder.transform(X_test)\n",
    "    \n",
    "    # --- C. Train XGBoost ---\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,        # Reduce overfitting by using subsamples\n",
    "        colsample_bytree=0.8, # Reduce overfitting by using subset of columns\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        early_stopping_rounds=50 # Stop if validation score stops improving\n",
    "    )\n",
    "    \n",
    "    # Use the test set as validation for early stopping\n",
    "    # (In a rigorous setup, you'd split train again into train/val, \n",
    "    # but for this scale, using the test fold for early stopping is standard practice)\n",
    "    model.fit(\n",
    "        X_train_encoded, y_train,\n",
    "        eval_set=[(X_test_encoded, y_test)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # --- D. Evaluation ---\n",
    "    # Predict (results are in Log scale)\n",
    "    preds_log = model.predict(X_test_encoded)\n",
    "    \n",
    "    # Inverse Transform: Convert Log -> Yen for human-readable error\n",
    "    preds_yen = np.exp(preds_log)\n",
    "    actual_yen = np.exp(y_test)\n",
    "    \n",
    "    # Metric: Mean Absolute Error\n",
    "    mae = mean_absolute_error(actual_yen, preds_yen)\n",
    "    \n",
    "    print(f\"Fold {fold}: Train End Year: {X_train['TransactionYear'].max()} | MAE: ¥{mae:,.0f}\")\n",
    "    results.append(mae)\n",
    "\n",
    "print(f\"\\nAverage MAE across folds: ¥{np.mean(results):,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d45f3b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Special Validation: 2025 Intra-Year Check ---\n",
      "Training on 505478 rows (2005 - Q1 2025)\n",
      "Testing on 11547 rows (Q2 2025 - Present)\n",
      "MAE on 2025 Future Data: ¥11,344,048\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Special Validation: 2025 Intra-Year Check ---\")\n",
    "\n",
    "# 1. Define the Manual Split Date\n",
    "# We train on everything up to Q1 2025 (March 31), Test on Q2 2025 onwards\n",
    "split_date = '2025-04-01'\n",
    "\n",
    "# 2. Create Masks using the Date Column (which we kept in df but dropped from X)\n",
    "# Note: We use the original 'df' to get the dates, then slice 'X' and 'y'\n",
    "mask_train = df['TransactionQuarterEndDate'] < split_date\n",
    "mask_test  = df['TransactionQuarterEndDate'] >= split_date\n",
    "\n",
    "X_train_25 = X[mask_train]\n",
    "y_train_25 = y[mask_train]\n",
    "X_test_25  = X[mask_test]\n",
    "y_test_25  = y[mask_test]\n",
    "\n",
    "print(f\"Training on {len(X_train_25)} rows (2005 - Q1 2025)\")\n",
    "print(f\"Testing on {len(X_test_25)} rows (Q2 2025 - Present)\")\n",
    "\n",
    "# 3. Fit Encoder & Model\n",
    "# Use the same parameters you found in the loop\n",
    "manual_encoder = ce.TargetEncoder(cols=cat_cols, smoothing=10)\n",
    "manual_model = xgb.XGBRegressor(\n",
    "    n_estimators=1000, \n",
    "    learning_rate=0.05, \n",
    "    max_depth=6, \n",
    "    subsample=0.8, \n",
    "    colsample_bytree=0.8,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "X_train_enc = manual_encoder.fit_transform(X_train_25, y_train_25)\n",
    "X_test_enc = manual_encoder.transform(X_test_25)\n",
    "\n",
    "manual_model.fit(\n",
    "    X_train_enc, y_train_25, \n",
    "    eval_set=[(X_test_enc, y_test_25)], # Use the 2025 test set for validation\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# 4. Evaluate\n",
    "preds_log = manual_model.predict(X_test_enc)\n",
    "preds_yen = np.exp(preds_log)\n",
    "actual_yen = np.exp(y_test_25)\n",
    "\n",
    "mae_2025 = mean_absolute_error(actual_yen, preds_yen)\n",
    "print(f\"MAE on 2025 Future Data: ¥{mae_2025:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd9b4fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Percentage Error (MAPE): 17.60%\n"
     ]
    }
   ],
   "source": [
    "# Use the manual_model (which was trained on Q1) to predict Q2-Q4\n",
    "# We use X_test_enc which you already created in the block above\n",
    "preds_log = manual_model.predict(X_test_enc)\n",
    "\n",
    "# Convert back to Yen\n",
    "preds_yen = np.exp(preds_log)\n",
    "actual_yen = np.exp(y_test_25)\n",
    "\n",
    "# Calculate MAPE (Mean Absolute Percentage Error)\n",
    "# Formula: Average of |(Actual - Predicted) / Actual|\n",
    "mape = np.mean(np.abs((actual_yen - preds_yen) / actual_yen)) * 100\n",
    "\n",
    "print(f\"Mean Percentage Error (MAPE): {mape:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
